{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Combined Graph Dataframe Generator\n",
        "\n",
        "This notebook creates code to generate the combined data set showing results for all 32 graphs."
      ],
      "metadata": {
        "id": "6CcOvx8FaUxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ],
      "metadata": {
        "id": "IPQkOz6yakQR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlSmEOA7NFCg"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import pandas as pd\n",
        "import sys\n",
        "import typing_extensions as typing\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from google.colab import drive\n",
        "from scipy.stats import f, t\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import zscore\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define Data Analysis Functions"
      ],
      "metadata": {
        "id": "8aiFhMz3api6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_df(model:str,temperature:int,maxout:int) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Obtains the dataframe for a given model, temperature, and maximum number of\n",
        "  output tokens.\n",
        "\n",
        "  Args:\n",
        "\n",
        "    model: model name\n",
        "    temperature: temperature parameter\n",
        "    maxout: maximum number of output tokens\n",
        "\n",
        "  Returns:\n",
        "\n",
        "    df: dataframe containing the results for the given model, temperature, and\n",
        "    maximum number of output tokens\n",
        "  \"\"\"\n",
        "  filename = (f'/data/path_length_rt_data/'\n",
        "              f'results_model_{model}_temp{temperature}_maxout'\n",
        "              f'{maxout}.csv')\n",
        "  df = pd.read_csv(filename)\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "def get_hallucination_rate(model:str,temperature:int,maxout:int) -> int:\n",
        "  \"\"\"\n",
        "  Obtains the hallucination rate for a given model, temperature, and maximum\n",
        "  number of output tokens.\n",
        "\n",
        "  Args:\n",
        "\n",
        "    model: model name\n",
        "    temperature: temperature parameter\n",
        "    maxout: maximum number of output tokens\n",
        "\n",
        "  Returns:\n",
        "\n",
        "    rate: the hallucination rate\n",
        "  \"\"\"\n",
        "  filename = (f'/data/semantic_graphs'\n",
        "            f'graph_model_{model}_'\n",
        "            f'temp{temperature}_maxoutput{maxout}.txt')\n",
        "\n",
        "  f = open(filename, \"r\")\n",
        "  formatted_graphs_string = f.read()\n",
        "  f.close()\n",
        "  formatted_graphs = ast.literal_eval(formatted_graphs_string)\n",
        "\n",
        "  !gdown 1qP8e6g78x9UwV1BJZIr2Jr_FwkoPbRjB --quiet\n",
        "  df = pd.read_csv('priming_data.csv', engine='python')\n",
        "  words_df = df[df['type'] != 'nw']\n",
        "  words_df = words_df[words_df['RT'] != '#NULL!']\n",
        "  words_df['RT'] = [int(i) for i in words_df[\"RT\"]]\n",
        "  words_df['RT'] = zscore(words_df['RT'])\n",
        "  words_df = words_df.reset_index(drop=True)\n",
        "  unique_words = np.concatenate([np.unique(words_df['prime']),\n",
        "                                np.unique(words_df['target'])])\n",
        "  unique_words = [w.lower() for w in unique_words]\n",
        "\n",
        "  # Convert unique_words to a set for O(1) lookups\n",
        "  unique_words_set = set(unique_words)\n",
        "\n",
        "  # Pre-calculate total number of triples\n",
        "  total_triples = sum(len(l) for l in formatted_graphs)\n",
        "\n",
        "  # Use a single loop for improved efficiency\n",
        "  hallucinations = [\n",
        "      triple[key]\n",
        "      for l in formatted_graphs\n",
        "      for triple in l\n",
        "      for key in ('subject', 'target')\n",
        "      if triple[key] not in unique_words_set\n",
        "  ]\n",
        "\n",
        "  # Calculate hallucination percentage\n",
        "  rate = len(hallucinations) / total_triples\n",
        "  return rate\n",
        "\n",
        "def connected_graph(df:pd.DataFrame) -> bool:\n",
        "  \"\"\"\n",
        "  Determines if a graph is connected.\n",
        "\n",
        "  Args:\n",
        "\n",
        "    df: dataframe containing the summary of graph data for a given semantic\n",
        "    graph.\n",
        "\n",
        "  Returns:\n",
        "\n",
        "    True if the graph is connected, False otherwise\n",
        "  \"\"\"\n",
        "  if np.nanmax(df['distance']) == float('inf'):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "\n",
        "def max_path(df:pd.DataFrame) -> int:\n",
        "  \"\"\"\n",
        "  Computes the maximum path length in a graph.\n",
        "\n",
        "  Args:\n",
        "\n",
        "    df: dataframe containing the summary of graph data for a given semantic\n",
        "    graph.\n",
        "\n",
        "  Returns:\n",
        "\n",
        "    The maximum path length in the graph.\n",
        "  \"\"\"\n",
        "  return np.nanmax(df['distance'][np.isfinite(df['distance'])])\n",
        "\n",
        "\n",
        "def get_log_likelihood(df:pd.DataFrame) -> float:\n",
        "  \"\"\"\n",
        "  Learns a mixed-effects model predicting the relationship between minimum path\n",
        "  length between prime and target words and reaction time, and then outputs\n",
        "  the log-likelihood of the Hutchinson et al. data according to that model.\n",
        "\n",
        "  Args:\n",
        "\n",
        "    df: dataframe containing the summary of graph data for a given semantic\n",
        "    graph.\n",
        "\n",
        "  Returns:\n",
        "\n",
        "    The log-likelihood of the Hutchinson et al. data according to the model.\n",
        "  \"\"\"\n",
        "  max_distance = np.nanmax(df['distance'][np.isfinite(df['distance'])])\n",
        "  df['distance'] = df['distance'].replace(np.inf, max_distance + 1)\n",
        "  df['z_distance'] = zscore(df['distance'])\n",
        "  df['Trial'] = zscore(df['Trial'])\n",
        "  mod = smf.mixedlm('RT ~ z_distance + Trial + Session',\n",
        "            data=df,\n",
        "            groups=df[\"Subject\"],\n",
        "            re_formula=\"1 + z_distance + Trial + Session\").fit()\n",
        "  return mod.llf\n",
        "\n",
        "\n",
        "def get_results(model:str,temperature:int,maxout:int) -> dict:\n",
        "  \"\"\"\n",
        "  Compute all ey data points for a given model, temperature, and maximum number\n",
        "  of output tokens.\n",
        "\n",
        "  Args:\n",
        "\n",
        "    model: model name\n",
        "    temperature: temperature parameter\n",
        "    maxout: maximum number of output tokens\n",
        "\n",
        "  Returns:\n",
        "    A dictionary containing the key data points for the given model, temperature,\n",
        "    and maximum number of output tokens.\n",
        "  \"\"\"\n",
        "  df = get_df(model,temperature,maxout)\n",
        "  return {\n",
        "          \"model\":model,\n",
        "          \"temperature\":temperature,\n",
        "          \"maxout\":maxout,\n",
        "          \"hallucination_rate\":get_hallucination_rate(model,temperature,maxout),\n",
        "          \"connected_graph\":connected_graph(df),\n",
        "          \"max_path\":max_path(df),\n",
        "          \"log_likelihood\":get_log_likelihood(df)\n",
        "  }"
      ],
      "metadata": {
        "id": "3vbk_8ErNJi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate and Save Dataframe"
      ],
      "metadata": {
        "id": "TGlP3YwYbQw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for i in tqdm([0,.3,.7,1]):\n",
        "  for j in tqdm(np.arange(512,2049,512)):\n",
        "    results.append(get_results(\"gemini-1.5-pro-001\",i,j))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "filename = '/data/combined_graph_data.csv'\n",
        "\n",
        "results_df.to_csv(filename)"
      ],
      "metadata": {
        "id": "Nagz78-aRJOi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}